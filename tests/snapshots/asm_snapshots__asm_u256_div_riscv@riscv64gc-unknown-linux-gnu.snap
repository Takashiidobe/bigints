---
source: tests/asm_snapshots.rs
expression: asm
---
.section .text.<bigints::u256::Uint256 as core::ops::arith::Div>::div,"ax",@progbits
	.globl	<bigints::u256::Uint256 as core::ops::arith::Div>::div
	.p2align	1
.type	<bigints::u256::Uint256 as core::ops::arith::Div>::div,@function
<bigints::u256::Uint256 as core::ops::arith::Div>::div:
	.cfi_startproc
	addi sp, sp, -224
	.cfi_def_cfa_offset 224
	sd ra, 216(sp)
	sd s0, 208(sp)
	sd s1, 200(sp)
	sd s2, 192(sp)
	sd s3, 184(sp)
	sd s4, 176(sp)
	sd s5, 168(sp)
	sd s6, 160(sp)
	sd s7, 152(sp)
	sd s8, 144(sp)
	sd s9, 136(sp)
	sd s10, 128(sp)
	sd s11, 120(sp)
	.cfi_offset ra, -8
	.cfi_offset s0, -16
	.cfi_offset s1, -24
	.cfi_offset s2, -32
	.cfi_offset s3, -40
	.cfi_offset s4, -48
	.cfi_offset s5, -56
	.cfi_offset s6, -64
	.cfi_offset s7, -72
	.cfi_offset s8, -80
	.cfi_offset s9, -88
	.cfi_offset s10, -96
	.cfi_offset s11, -104
	.cfi_remember_state
	ld s4, 16(a2)
	ld a5, 24(a2)
	or a3, a5, s4
	mv s11, a0
	beqz a3, .LBB_8
	ld t6, 24(a1)
	bne t6, a5, .LBB_15
	ld a3, 16(a1)
	bne a3, s4, .LBB_16
	ld s6, 8(a1)
	ld a3, 8(a2)
	bne s6, a3, .LBB_26
	ld t4, 0(a1)
	ld s5, 0(a2)
	mv t5, s4
	mv t3, s6
	bltu t4, s5, .LBB_17
	sd s11, 24(sp)
	beqz a5, .LBB_28
.LBB_6:
	srli a1, a5, 1
	lui a6, 349525
	lui a7, 209715
	lui t0, 61681
	lui s1, 4112
	srli t1, t4, 1
	srli t2, t3, 1
	or a4, a5, a1
	addi s0, a6, 1365
	addi a0, a7, 819
	addi a2, t0, -241
	addi s1, s1, 257
	srli a1, a4, 2
	or a6, a4, a1
	slli a4, s0, 32
	add a4, a4, s0
	slli a3, a0, 32
	add a0, a0, a3
	slli a3, a2, 32
	add a2, a2, a3
	slli a3, s1, 32
	add a3, a3, s1
	srli a1, a6, 4
	or s1, a6, a1
	srli a1, s1, 8
	or s1, s1, a1
	srli a1, s1, 16
	or s1, s1, a1
	srli a1, s1, 32
	or a1, a1, s1
	not s1, a1
	srli a1, s1, 1
	and a1, a1, a4
	srli a4, t5, 1
	sub s1, s1, a1
	and a1, s1, a0
	srli s1, s1, 2
	and a0, a0, s1
	srli s1, s5, 1
	add a0, a0, a1
	srli a1, a0, 4
	add a0, a0, a1
	srli a1, s6, 1
	and a0, a0, a2
	mul s0, a0, a3
	srli s0, s0, 56
	seqz a0, s0
	negw a2, s0
	srl a2, t6, a2
	addi a0, a0, -1
	and s2, a0, a2
	not a0, s0
	sll a2, t6, s0
	srl a3, a4, a0
	or s3, a2, a3
	srli a2, s4, 1
	sll s10, t3, s0
	sll t0, t5, s0
	sll s7, s6, s0
	sll s8, s4, s0
	sll a3, a5, s0
	srl a4, t1, a0
	srl s11, t2, a0
	srl s4, s1, a0
	srl s1, a2, a0
	or s1, s1, a3
	srl s9, a1, a0
	bgeu s2, s1, .LBB_20
	mv a0, s3
	mv a1, s2
	mv a2, s1
	li a3, 0
	mv s6, t4
	sd t0, 8(sp)
	sd s2, 16(sp)
	mv s2, a4
	call __udivti3
	mv a4, s2
	ld s2, 16(sp)
	ld t0, 8(sp)
	mv t4, s6
	li a2, 0
	j .LBB_21
.LBB_8:
	ld s6, 8(a2)
	beqz s6, .LBB_18
	ld s7, 0(a2)
	ld s4, 0(a1)
	ld s5, 8(a1)
	ld s1, 16(a1)
	ld s0, 24(a1)
	mv a0, s1
	mv a1, s0
	mv a2, s7
	mv a3, s6
	call __udivti3
	mv s2, a0
	mul a0, a0, s6
	mulhu a2, s2, s7
	mul a1, a1, s7
	add a0, a0, a2
	mul a2, s2, s7
	sub s0, s0, a1
	sltu a1, s1, a2
	sub s0, s0, a0
	sub a1, s0, a1
	sub a0, s1, a2
	or a2, a0, a1
	beqz a2, .LBB_25
	srli a6, s7, 1
	lui a3, 349525
	lui a4, 209715
	lui a5, 61681
	lui s1, 4112
	addi a3, a3, 1365
	addi a4, a4, 819
	addi s0, a5, -241
	addi a2, s1, 257
	slli s1, a3, 32
	add s1, s1, a3
	slli a5, a4, 32
	add a5, a5, a4
	slli a3, s0, 32
	add a3, a3, s0
	slli a4, a2, 32
	add a4, a4, a2
	bnez s6, .LBB_33
	or s0, s7, a6
	srli a2, s0, 2
	or s0, s0, a2
	srli a2, s0, 4
	or s0, s0, a2
	srli a2, s0, 8
	or s0, s0, a2
	srli a2, s0, 16
	or s0, s0, a2
	srli a2, s0, 32
	or a2, a2, s0
	not s0, a2
	srli a2, s0, 1
	and a2, a2, s1
	sub s0, s0, a2
	and a2, s0, a5
	srli s0, s0, 2
	and a5, a5, s0
	add a2, a2, a5
	srli a5, a2, 4
	add a2, a2, a5
	and a2, a2, a3
	mul a2, a2, a4
	srli a2, a2, 56
	addi a3, a2, 64
	not a7, a3
	addi a5, a3, -64
	sll s10, s7, a3
	bgez a5, .LBB_34
.LBB_12:
	sll a2, s6, a3
	srl s1, a6, a7
	or s6, a2, s1
	sll a2, a0, a3
	bgez a5, .LBB_35
.LBB_13:
	sll a1, a1, a3
	srli a0, a0, 1
	srl a0, a0, a7
	or a0, a0, a1
	negw s0, a3
	andi a1, s0, 127
	addi s1, a1, -64
	srai s3, a5, 63
	bgez s1, .LBB_36
.LBB_14:
	srl a6, s4, s0
	not a1, a1
	slli a4, s5, 1
	sll a1, a4, a1
	or a1, a6, a1
	j .LBB_37
.LBB_15:
	sltu a3, t6, a5
	bnez a3, .LBB_17
	j .LBB_27
.LBB_16:
	sltu a3, a3, s4
	beqz a3, .LBB_27
.LBB_17:
	sd zero, 0(s11)
	sd zero, 8(s11)
	sd zero, 16(s11)
	j .LBB_59
.LBB_18:
	ld s0, 0(a2)
	beqz s0, .LBB_125
	ld a0, 24(a1)
	divu s3, a0, s0
	ld s2, 16(a1)
	mul a2, s3, s0
	sub a2, a0, a2
	mv a0, s2
	mv s1, a1
	mv a1, a2
	mv a2, s0
	li a3, 0
	call __udivti3
	ld s5, 8(s1)
	mv s4, a0
	mul a0, a0, s0
	sub a1, s2, a0
	mv a0, s5
	mv a2, s0
	li a3, 0
	call __udivti3
	ld a2, 0(s1)
	mv s1, a0
	mul a0, a0, s0
	sub a1, s5, a0
	mv a0, a2
	mv a2, s0
	li a3, 0
	call __udivti3
	sd a0, 0(s11)
	sd s1, 8(s11)
	sd s4, 16(s11)
	sd s3, 24(s11)
	j .LBB_119
.LBB_20:
	li a2, 0
	li a0, -1
.LBB_21:
	sll a7, t4, s0
	sll t2, s5, s0
	or a6, s10, a4
	or t0, t0, s11
	or t1, s7, s4
	mulhu a3, s1, a0
	mul a1, a2, a0
	mul a4, s1, a0
	add a3, a3, a1
	sub a1, s2, a3
	sltu a5, s3, a4
	sub a1, a1, a5
	or a5, s8, s9
	beqz a1, .LBB_23
	li a2, 0
	ld t3, 24(sp)
	j .LBB_67
.LBB_23:
	sub a1, s3, a4
	mulhu s0, a0, a5
	ld t3, 24(sp)
	beq s0, a1, .LBB_60
	sltu s0, a1, s0
	bnez s0, .LBB_61
	j .LBB_66
.LBB_25:
	mv a0, s4
	mv a1, s5
	mv a2, s7
	mv a3, s6
	call __udivti3
	li s0, 0
	j .LBB_58
.LBB_26:
	sltu a3, s6, a3
	bnez a3, .LBB_17
.LBB_27:
	ld t4, 0(a1)
	ld t3, 8(a1)
	ld t5, 16(a1)
	ld s5, 0(a2)
	ld s6, 8(a2)
	sd s11, 24(sp)
	bnez a5, .LBB_6
.LBB_28:
	beqz s4, .LBB_68
	srli a2, s4, 1
	lui a4, 349525
	lui a5, 209715
	lui s1, 61681
	or s0, s4, a2
	addi a1, a4, 1365
	addi a5, a5, 819
	addi s1, s1, -241
	srli a2, s0, 2
	or s0, s0, a2
	slli a4, a1, 32
	add a1, a1, a4
	slli a4, a5, 32
	add a4, a4, a5
	slli a5, s1, 32
	add a5, a5, s1
	srli a2, s0, 4
	or s0, s0, a2
	srli a2, s0, 8
	or s0, s0, a2
	srli a2, s0, 16
	or s0, s0, a2
	srli a2, s0, 32
	or a2, a2, s0
	not s1, a2
	srli a2, s1, 1
	and a1, a1, a2
	sub s1, s1, a1
	and a1, s1, a4
	srli s1, s1, 2
	and a4, a4, s1
	lui a2, 4112
	addi a2, a2, 257
	add a1, a1, a4
	srli a4, a1, 4
	add a1, a1, a4
	slli a4, a2, 32
	and a1, a1, a5
	add a2, a2, a4
	mul s0, a1, a2
	srli s0, s0, 56
	beqz s0, .LBB_69
.LBB_30:
	andi t0, s0, 63
	beqz t0, .LBB_70
	seqz t2, s4
	negw a4, t0
	sll a1, s6, s0
	srl a2, s5, a4
	or a7, a1, a2
	beqz s4, .LBB_72
	srl a1, s6, a4
	sll a2, s4, s0
	or a6, a1, a2
	j .LBB_73
.LBB_33:
	srli a2, s6, 1
	or s0, s6, a2
	srli a2, s0, 2
	or s0, s0, a2
	srli a2, s0, 4
	or s0, s0, a2
	srli a2, s0, 8
	or s0, s0, a2
	srli a2, s0, 16
	or s0, s0, a2
	srli a2, s0, 32
	or a2, a2, s0
	not s0, a2
	srli a2, s0, 1
	and a2, a2, s1
	sub s0, s0, a2
	and a2, s0, a5
	srli s0, s0, 2
	and a5, a5, s0
	add a2, a2, a5
	srli a5, a2, 4
	add a2, a2, a5
	and a2, a2, a3
	mul a3, a2, a4
	srli a3, a3, 56
	not a7, a3
	addi a5, a3, -64
	sll s10, s7, a3
	bltz a5, .LBB_12
.LBB_34:
	mv s6, s10
	sll a2, a0, a3
	bltz a5, .LBB_13
.LBB_35:
	mv a0, a2
	negw s0, a3
	andi a1, s0, 127
	addi s1, a1, -64
	srai s3, a5, 63
	bltz s1, .LBB_14
.LBB_36:
	srl a1, s5, a1
.LBB_37:
	and a2, s3, a2
	srl a4, s5, s0
	srai s1, s1, 63
	and a4, a4, s1
	or s7, a0, a4
	sll s8, s4, a3
	bltz a5, .LBB_39
	mv s5, s8
	or s4, a2, a1
	li s9, -1
	li s0, -1
	bltu s7, s6, .LBB_40
	j .LBB_41
.LBB_39:
	sll a0, s5, a3
	srli a3, s4, 1
	srl a3, a3, a7
	or s5, a0, a3
	or s4, a2, a1
	li s9, -1
	li s0, -1
	bgeu s7, s6, .LBB_41
.LBB_40:
	mv a0, s4
	mv a1, s7
	mv a2, s6
	li a3, 0
	call __udivti3
	mv s0, a0
.LBB_41:
	mulhu a0, s6, s0
	mul a1, s6, s0
	sltu a2, s4, a1
	add a0, a0, a2
	sub a0, s7, a0
	and s1, s3, s10
	beqz a0, .LBB_43
	li a0, 0
	j .LBB_49
.LBB_43:
	sub a2, s4, a1
	addi a1, s0, -1
.LBB_44:
	mulhu a3, s0, s1
	mul a4, a0, s1
	add a3, a3, a4
	beq a3, a2, .LBB_46
	sltu a2, a2, a3
	j .LBB_47
.LBB_46:
	mul a2, s0, s1
	sltu a2, s5, a2
.LBB_47:
	beqz a2, .LBB_49
	li a0, 0
	mulhu a2, s6, a1
	mul a3, s6, a1
	sltu a4, s4, a3
	sub a2, s7, a2
	sub a4, a2, a4
	mv s0, a1
	sub a2, s4, a3
	addi a1, a1, -1
	beqz a4, .LBB_44
.LBB_49:
	mulhu a1, s0, s1
	mul a2, s0, s6
	mul a0, a0, s1
	add a1, a1, a2
	mul a2, s0, s1
	add a0, a0, a1
	sub a0, s4, a0
	sltu a1, s5, a2
	sub s4, a0, a1
	sub s5, s5, a2
	bgeu s4, s6, .LBB_51
	mv a0, s5
	mv a1, s4
	mv a2, s6
	li a3, 0
	call __udivti3
	mulhu a2, s6, a0
	mul a1, s6, a0
	sltu a3, s5, a1
	sub a2, s4, a2
	sub a2, a2, a3
	beqz a2, .LBB_52
	j .LBB_58
.LBB_51:
	li a0, -1
	mulhu a2, s6, a0
	mul a1, s6, a0
	sltu a3, s5, a1
	sub a2, s4, a2
	sub a2, a2, a3
	bnez a2, .LBB_58
.LBB_52:
	and a4, s3, s8
	sub a3, s5, a1
	and a1, a4, s9
.LBB_53:
	mulhu a4, a0, s1
	mul a2, a2, s1
	add a2, a2, a4
	beq a2, a3, .LBB_55
	sltu a2, a3, a2
	j .LBB_56
.LBB_55:
	mul a2, a0, s1
	sltu a2, a1, a2
.LBB_56:
	beqz a2, .LBB_58
	li a2, 0
	addi a0, a0, -1
	mulhu a3, s6, a0
	mul a4, s6, a0
	sltu a5, s5, a4
	sub a3, s4, a3
	sub a5, a3, a5
	sub a3, s5, a4
	beqz a5, .LBB_53
.LBB_58:
	sd a0, 0(s11)
	sd s0, 8(s11)
	sd s2, 16(s11)
.LBB_59:
	sd zero, 24(s11)
	j .LBB_119
.LBB_60:
	mul a1, a0, a5
	sltu s0, t0, a1
	beqz s0, .LBB_66
.LBB_61:
	addi a1, a0, -1
	j .LBB_65
.LBB_62:
	sltu s0, a1, s0
	addi a1, a0, -1
	bnez s0, .LBB_65
	j .LBB_66
.LBB_63:
	sub a1, s3, a4
	mulhu s0, a0, a5
	bne s0, a1, .LBB_62
	mul a1, a0, a5
	sltu s0, t0, a1
	addi a1, a0, -1
	beqz s0, .LBB_66
.LBB_65:
	mv a0, a1
	mulhu a3, s1, a1
	mul a1, a2, a1
	mul a4, s1, a0
	add a3, a3, a1
	sub a1, s2, a3
	sltu s0, s3, a4
	sub a1, a1, s0
	beqz a1, .LBB_63
.LBB_66:
	li a2, 0
.LBB_67:
	mulhu a1, a0, t2
	mul s1, a2, t2
	mul s0, a0, t2
	add a1, a1, s1
	mulhu s1, a0, t1
	sltu a7, a7, s0
	mul s0, a2, t1
	mul t1, a0, t1
	add s0, s0, s1
	mulhu s1, a0, a5
	mul a2, a2, a5
	mul a5, a0, a5
	add a2, a2, s1
	add t1, t1, a1
	sltu a1, t1, a1
	add a7, a7, t1
	add a1, a1, s0
	sltu s1, a7, t1
	sltu s0, a6, a7
	add a1, a1, s1
	add a5, a5, a1
	sltu a1, a5, a1
	add s0, s0, a5
	add a1, a1, a2
	sltu a2, s0, a5
	sltu a5, t0, s0
	add a1, a1, a2
	add a4, a4, a1
	sltu a1, a4, a1
	add a5, a5, a4
	add a1, a1, a3
	sltu a2, a5, a4
	sltu a3, s3, a5
	add a1, a1, a2
	add a1, a1, a3
	sltu a1, s2, a1
	sub a0, a0, a1
	sd a0, 0(t3)
	sd zero, 8(t3)
	sd zero, 16(t3)
	sd zero, 24(t3)
	j .LBB_119
.LBB_68:
	li s0, 64
	bnez s0, .LBB_30
.LBB_69:
	sd t4, 32(sp)
	sd t3, 40(sp)
	sd t5, 48(sp)
	sd t6, 56(sp)
	sd zero, 64(sp)
	sd zero, 72(sp)
	sd zero, 80(sp)
	j .LBB_88
.LBB_70:
	seqz a2, s4
	beqz s4, .LBB_81
	mv a6, s4
	mv a7, s6
	j .LBB_82
.LBB_72:
	mv a6, a7
	mv a7, s5
.LBB_73:
	sd zero, 64(sp)
	sd zero, 72(sp)
	sd zero, 80(sp)
	sd zero, 32(sp)
	sd zero, 40(sp)
	sd zero, 48(sp)
	sd zero, 56(sp)
	sd t4, 88(sp)
	sd t3, 96(sp)
	sd t5, 104(sp)
	sd t6, 112(sp)
	slli a1, t2, 3
	sll a2, t4, s0
	addi t1, sp, 32
	add a1, a1, t1
	sd a2, 0(a1)
	sll a2, t3, s0
	srl a5, t4, a4
	li s1, 16
	beqz s4, .LBB_75
	li s1, 8
.LBB_75:
	or a5, a5, a2
	add s1, s1, t1
	sll a2, t5, s0
	srl a3, t3, a4
	sd a5, 0(s1)
	li a5, 24
	li s1, 24
	beqz s4, .LBB_77
	li s1, 16
.LBB_77:
	sll t3, s5, s0
	addi t4, t2, -1
	or a3, a3, a2
	add s1, s1, t1
	addiw a2, t2, 4
	sll a0, t6, s0
	sd a3, 0(s1)
	srl a1, t5, a4
	bnez s4, .LBB_79
	li a5, 32
.LBB_79:
	and s5, t4, t3
	or a1, a1, a0
	add a5, a5, t1
	not a0, t2
	add a0, a0, a2
	li a3, 3
	sd a1, 0(a5)
	bltu a3, a0, .LBB_87
	slli a0, a0, 3
	addi a1, sp, 88
	slli a2, a2, 3
	addi a3, sp, 32
	add a0, a0, a1
	ld a0, 0(a0)
	add a2, a2, a3
	ld a1, 0(a2)
	li a3, 64
	sub a3, a3, t0
	srl a0, a0, a3
	or a0, a0, a1
	sd a0, 0(a2)
	j .LBB_87
.LBB_81:
	mv a6, s6
	mv a7, s5
.LBB_82:
	sd zero, 64(sp)
	sd zero, 72(sp)
	sd zero, 80(sp)
	sd zero, 32(sp)
	sd zero, 40(sp)
	sd zero, 48(sp)
	sd zero, 56(sp)
	slli a1, a2, 3
	addi a4, sp, 32
	add a1, a1, a4
	sd t4, 0(a1)
	li a5, 16
	bnez s4, .LBB_120
	add a5, a5, a4
	sd t3, 0(a5)
	li a3, 24
	li a5, 24
	bnez s4, .LBB_121
.LBB_84:
	addi a2, a2, -1
	add a5, a5, a4
	sd t5, 0(a5)
	bnez s4, .LBB_86
.LBB_85:
	li a3, 32
.LBB_86:
	and s5, a2, s5
	add a3, a3, a4
	sd t6, 0(a3)
.LBB_87:
	mv s6, a7
	mv s4, a6
.LBB_88:
	li a1, 0
	li t4, 1
	addi s2, sp, 32
	li s9, 6
	li s11, 1
	j .LBB_90
.LBB_89:
	beqz s10, .LBB_118
.LBB_90:
	mv s10, s11
	mv s7, a1
	beqz s11, .LBB_95
	addi a3, s10, 3
	bltu s9, a3, .LBB_123
	addi a0, s10, 2
	li a1, 7
	bgeu a0, a1, .LBB_122
	slli a3, a3, 3
	add s8, s2, a3
	ld s1, 0(s8)
	addi s11, s10, -1
	slli a0, a0, 3
	add s3, s2, a0
	ld s0, 0(s3)
	bgeu s1, s4, .LBB_96
.LBB_94:
	mv a0, s0
	mv a1, s1
	mv a2, s4
	li a3, 0
	call __udivti3
	li t4, 1
	mulhu a1, a0, s4
	mul a2, a0, s4
	sltu a3, s0, a2
	sub a4, s1, a1
	sub a4, a4, a3
	beqz a4, .LBB_97
	j .LBB_107
.LBB_95:
	ld s1, 56(sp)
	li a0, 2
	addi s8, sp, 56
	slli a0, a0, 3
	add s3, s2, a0
	ld s0, 0(s3)
	bltu s1, s4, .LBB_94
.LBB_96:
	li a0, -1
	mulhu a1, a0, s4
	mul a2, a0, s4
	sltu a3, s0, a2
	sub a4, s1, a1
	sub a4, a4, a3
	bnez a4, .LBB_107
.LBB_97:
	addi a7, s10, 1
	li a3, 5
	bltu a3, s10, .LBB_124
	slli a3, a7, 3
	add a3, a3, s2
	ld t2, 0(a3)
	sub a3, s0, a2
	mulhu t0, a0, s6
	mul a6, a0, s6
	beq t0, a3, .LBB_101
	sltu a3, a3, t0
	bnez a3, .LBB_102
.LBB_100:
	li s1, 0
	j .LBB_109
.LBB_101:
	sltu a3, t2, a6
	beqz a3, .LBB_100
.LBB_102:
	addi a5, a0, -1
	j .LBB_106
.LBB_103:
	sltu a3, a3, a5
	addi a5, a0, -1
	bnez a3, .LBB_106
	j .LBB_107
.LBB_104:
	sub a3, s0, a2
	mulhu a5, a0, s6
	bne a5, a3, .LBB_103
	mul a3, a0, s6
	sltu a3, t2, a3
	addi a5, a0, -1
	beqz a3, .LBB_107
.LBB_106:
	mv a0, a5
	mulhu a1, a5, s4
	mul a2, a5, s4
	sltu a3, s0, a2
	sub a5, s1, a1
	sub a5, a5, a3
	beqz a5, .LBB_104
.LBB_107:
	li s1, 0
	bltu s9, s10, .LBB_110
	addi a7, s10, 1
	slli a3, a7, 3
	add a3, a3, s2
	ld t2, 0(a3)
	mulhu a5, a0, s6
	mul a3, s1, s6
	add t0, a5, a3
	mul a6, a0, s6
.LBB_109:
	mulhu t1, a0, s5
	mul s1, s1, s5
	mul s0, a0, s5
	slli a5, s10, 3
	slli a3, a7, 3
	add t1, t1, s1
	add a5, a5, s2
	add t3, s2, a3
	ld s1, 0(a5)
	add a6, a6, t1
	sltu a4, a6, t1
	add a4, a4, t0
	sub a3, s1, s0
	sltu s1, s1, s0
	sd a3, 0(a5)
	add s1, s1, a6
	sltu a3, s1, a6
	sub a5, t2, s1
	sltu s1, t2, s1
	add a3, a3, a4
	sd a5, 0(t3)
	ld s0, 0(s3)
	add a5, a3, s1
	sltu s1, a5, a3
	li a4, 1
	j .LBB_111
.LBB_110:
	li a4, 0
	li a5, 0
	li s1, 0
	li a7, -1
.LBB_111:
	add a2, a2, a5
	add a1, a1, s1
	sltu a3, a2, a5
	sub a5, s0, a2
	sd a5, 0(s3)
	ld a5, 0(s8)
	add a1, a1, a3
	sltu a2, s0, a2
	add a1, a1, a2
	sub a2, a5, a1
	sd a2, 0(s8)
	bltu a5, a1, .LBB_113
	mv a1, a0
	beq s10, t4, .LBB_89
	j .LBB_117
.LBB_113:
	beqz a4, .LBB_115
	slli a1, s10, 3
	add a1, a1, s2
	ld a2, 0(a1)
	slli a7, a7, 3
	add a7, a7, s2
	add a3, a2, s5
	sd a3, 0(a1)
	ld a1, 0(a7)
	sltu a2, a3, a2
	add a3, a1, s6
	sltu a1, a3, a1
	add a2, a2, a3
	sltu a3, a2, a3
	sd a2, 0(a7)
	or a1, a1, a3
	j .LBB_116
.LBB_115:
	li a1, 0
.LBB_116:
	ld a2, 0(s3)
	addi a0, a0, -1
	add a3, a2, s4
	sltu a2, a3, a2
	add a1, a1, a3
	sltu a3, a1, a3
	sd a1, 0(s3)
	ld a1, 0(s8)
	or a2, a2, a3
	slli a2, a2, 32
	srli a2, a2, 32
	add a1, a1, a2
	sd a1, 0(s8)
	mv a1, a0
	beq s10, t4, .LBB_89
.LBB_117:
	mv a1, s7
	j .LBB_89
.LBB_118:
	ld a1, 24(sp)
	sd a0, 0(a1)
	sd s7, 8(a1)
	sd zero, 16(a1)
	sd zero, 24(a1)
.LBB_119:
	ld ra, 216(sp)
	ld s0, 208(sp)
	ld s1, 200(sp)
	ld s2, 192(sp)
	ld s3, 184(sp)
	ld s4, 176(sp)
	ld s5, 168(sp)
	ld s6, 160(sp)
	ld s7, 152(sp)
	ld s8, 144(sp)
	ld s9, 136(sp)
	ld s10, 128(sp)
	ld s11, 120(sp)
	.cfi_restore ra
	.cfi_restore s0
	.cfi_restore s1
	.cfi_restore s2
	.cfi_restore s3
	.cfi_restore s4
	.cfi_restore s5
	.cfi_restore s6
	.cfi_restore s7
	.cfi_restore s8
	.cfi_restore s9
	.cfi_restore s10
	.cfi_restore s11
	addi sp, sp, 224
	.cfi_def_cfa_offset 0
	ret
.LBB_120:
	.cfi_restore_state
	li a5, 8
	add a5, a5, a4
	sd t3, 0(a5)
	li a3, 24
	li a5, 24
	beqz s4, .LBB_84
.LBB_121:
	li a5, 16
	addi a2, a2, -1
	add a5, a5, a4
	sd t5, 0(a5)
	beqz s4, .LBB_85
	j .LBB_86
.LBB_122:
.Lpcrel_hi25:
	auipc a1, %pcrel_hi(.Lanon.9)
	addi a2, a1, %pcrel_lo(.Lpcrel_hi25)
	li a1, 7
	call core::panicking::panic_bounds_check
.LBB_123:
.Lpcrel_hi24:
	auipc a0, %pcrel_hi(.Lanon.8)
	addi a2, a0, %pcrel_lo(.Lpcrel_hi24)
	li a1, 7
	mv a0, a3
	call core::panicking::panic_bounds_check
.LBB_124:
.Lpcrel_hi26:
	auipc a0, %pcrel_hi(.Lanon.10)
	addi a2, a0, %pcrel_lo(.Lpcrel_hi26)
	li a1, 7
	mv a0, a7
	call core::panicking::panic_bounds_check
.LBB_125:
.Lpcrel_hi23:
	auipc a0, %pcrel_hi(.Lanon.11)
	addi a0, a0, %pcrel_lo(.Lpcrel_hi23)
	call core::panicking::panic_const::panic_const_div_by_zero
